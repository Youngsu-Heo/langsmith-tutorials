{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Agent\n",
    "\n",
    "https://docs.smith.langchain.com/evaluation/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import environ as env\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env-leo', override=True)\n",
    "langsmith_key = env.get('LANGSMITH_API_KEY')\n",
    "openai_api_key = env.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Spit some bars about the topic\\n\\n{agent_scratchpad}\"),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "@tool\n",
    "def get_encouragement(request: str) -> str:\n",
    "    \"\"\"Get some encouragement.\"\"\"\n",
    "    return \"You can do it!\"\n",
    "\n",
    "tools = [get_encouragement]\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Since chains and agents can be stateful (they can have memory),\n",
    "# create a constructor to pass in to the run_on_dataset method.\n",
    "def create_agent():\n",
    "    agent = create_openai_functions_agent(\n",
    "        llm,\n",
    "        tools=[get_encouragement],\n",
    "        prompt=prompt,\n",
    "    )\n",
    "    return AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "dataset_name = \"Rap Battle Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'agent-test-1' at:\n",
      "https://smith.langchain.com/o/08d5427c-65f6-54e0-ba99-91184efa5aca/datasets/8257acae-3a07-4903-bb7c-9a7b93b8ff65/compare?selectedSessions=47bf71e1-8aad-45e2-8e42-a39b0d263bff\n",
      "\n",
      "View all tests for Dataset Rap Battle Dataset at:\n",
      "https://smith.langchain.com/o/08d5427c-65f6-54e0-ba99-91184efa5aca/datasets/8257acae-3a07-4903-bb7c-9a7b93b8ff65\n",
      "[------------------------------------------------->] 2/2"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_name': 'agent-test-1',\n",
       " 'results': {'c0b1a426-dbb1-4bc7-98ae-1d7137988fe9': {'input': {'question': 'a rap battle between Atticus Finch and Cicero'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment='The criterion for this task is \"helpfulness: Is the submission helpful, insightful, and appropriate?\"\\n\\nStep 1: Assessing Helpfulness\\nThe submission is a creative interpretation of the given task, which is a rap battle between Atticus Finch and Cicero. It provides a clear and engaging narrative of how such a battle might unfold, highlighting the strengths and characteristics of both characters. Therefore, it can be considered helpful in understanding and visualizing the given scenario.\\n\\nStep 2: Assessing Insightfulness\\nThe submission is insightful as it captures the essence of both characters - Atticus Finch\\'s dedication to justice and Cicero\\'s rhetorical prowess. It also insightfully sets up the context of a rap battle between these two figures, making it an engaging and thought-provoking piece.\\n\\nStep 3: Assessing Appropriateness\\nThe submission is appropriate as it sticks to the given task and does not include any offensive or inappropriate content. It maintains a respectful tone towards both characters and presents a creative and entertaining scenario that fits the task.\\n\\nBased on these assessments, the submission meets all the criteria.\\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('add28e29-85fc-4986-9272-ef0b693941e2'))}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='harmfulness', score=0, value='N', comment='The criterion for this assessment is whether the submission is harmful, offensive, or inappropriate.\\n\\nLooking at the submission, it is a creative rap battle between two historical figures, Atticus Finch and Cicero. The language used is respectful and there are no harmful, offensive, or inappropriate words or phrases. The content is suitable for all audiences.\\n\\nTherefore, the submission is not harmful, offensive, or inappropriate.\\n\\nN', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('1ad9c580-4f2f-46ca-a5ae-eb00d1733cc3'))}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='cliche', score=1, value='Y', comment='The criterion asks if the lyrics are cliche. To determine this, we need to assess if the lyrics use overused phrases or themes.\\n\\nLooking at the submission, the lyrics do use some common phrases and themes found in rap battles. Phrases like \"going head to head,\" \"battle of words,\" and \"clash of the greats\" are often used in similar contexts. The theme of two opponents facing off in a battle of skill is also a common trope in rap battles.\\n\\nHowever, the lyrics also contain unique elements. The use of historical and literary figures like Atticus Finch and Cicero is not common in rap battles. The lyrics also delve into the specific characteristics of these figures, such as Atticus Finch\\'s defense of the innocent and Cicero\\'s rhetorical skills.\\n\\nTherefore, while the lyrics do contain some cliche elements, they are not entirely cliche due to the unique elements present.\\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('ec6948fa-a382-4c9c-ac47-2c1924b174cd'))}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=False, value=None, comment=None, correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 3.042418,\n",
       "   'run_id': '410df234-fe03-4b88-8bf7-36f8f51d04f6',\n",
       "   'output': {'question': 'a rap battle between Atticus Finch and Cicero',\n",
       "    'output': \"In the courtroom, Atticus Finch stands tall,\\nWith wisdom and courage, he never falls.\\nDefending the innocent with all his might,\\nHis words are sharp, his arguments tight.\\n\\nBut Cicero, the orator from ancient Rome,\\nHis words cut deep, he's never alone.\\nWith rhetoric and logic, he makes his case,\\nIn the forum, he's the one to embrace.\\n\\nAtticus Finch, a man of honor and grace,\\nCicero, a legend in every place.\\nIn this rap battle of wit and skill,\\nWho will emerge victorious, who will thrill?\\n\\nTwo masters of language, going head to head,\\nIn a battle of words, where egos are fed.\\nAtticus Finch and Cicero, a clash of the greats,\\nLet the rap battle begin, let's see their fates.\"},\n",
       "   'reference': {'must_mention': ['lawyer', 'justice']}},\n",
       "  '148a4124-29c5-41cf-9cd5-386b83b8f1f5': {'input': {'question': 'a rap battle between Barbie and Oppenheimer'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment='The criterion for this task is \"helpfulness: Is the submission helpful, insightful, and appropriate?\"\\n\\n1. Helpfulness: The submission is a creative interpretation of the given task, which is a rap battle between Barbie and Oppenheimer. It provides a comparison between the two characters in a rap format, which is what the task asked for. Therefore, it can be considered helpful.\\n\\n2. Insightfulness: The submission provides insights into the characters of Barbie and Oppenheimer, highlighting their differences in a clever and entertaining way. It uses their known characteristics to create a rap battle, which can be considered insightful.\\n\\n3. Appropriateness: The submission is appropriate as it sticks to the task given and does not include any offensive or inappropriate content. It maintains a respectful tone while still being entertaining.\\n\\nBased on this analysis, the submission meets all the criteria.\\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('87babbd6-4c7a-4bcf-b26e-ce15de3bcf3f'))}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='harmfulness', score=0, value='N', comment='The criterion for this assessment is whether the submission is harmful, offensive, or inappropriate.\\n\\nLooking at the submission, it is a creative rap battle between the characters Barbie and Oppenheimer. The rap does not contain any harmful or offensive language. It does not promote violence, hate speech, or any form of discrimination. It is also not inappropriate as it does not contain any explicit or adult content.\\n\\nTherefore, the submission is not harmful, offensive, or inappropriate.\\n\\nN', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('237eabdc-24e4-4baa-890b-eccd7260211c'))}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='cliche', score=1, value='Y', comment='The criterion is asking whether the lyrics are cliche or not. To determine this, we need to assess if the lyrics use overused or predictable phrases, ideas, or themes. \\n\\nLooking at the submission, the lyrics do use some common rap battle themes such as comparing intelligence, looks, and status. Phrases like \"Barbie\\'s all glitz and glam, shining like a star,\" \"Oppenheimer\\'s in the lab, making atoms shuffle,\" and \"In this rap battle, he\\'s sitting on the throne\" are somewhat predictable in a rap battle context. \\n\\nHowever, the specific comparison between Barbie and Oppenheimer is unique and the lyrics also incorporate specific details about each character, such as Barbie living in a dream house and Oppenheimer creating bombs. \\n\\nWhile there are some common themes, the lyrics also have unique elements. Therefore, the lyrics are not entirely cliche, but they are also not entirely unique. \\n\\nGiven the binary nature of the criterion (Y for cliche, N for entirely unique), the lyrics do not fully meet either description. However, since the lyrics do contain some common themes and phrases, they lean more towards being somewhat cliche than being entirely unique.\\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('8dfc3f98-0019-4224-8b26-cc5f45f0abd3'))}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=False, value=None, comment=None, correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 6.729425,\n",
       "   'run_id': '42334705-983a-4c4a-ad5d-1112861852c0',\n",
       "   'output': {'question': 'a rap battle between Barbie and Oppenheimer',\n",
       "    'output': \"Barbie, Oppenheimer, let's see who's the wiser,\\nIn this rap battle, who's gonna be the survivor?\\nBarbie's all glitz and glam, shining like a star,\\nOppenheimer dropping knowledge, reaching for the far.\\n\\nBarbie's got the looks, but Oppenheimer's got the brains,\\nCreating bombs that caused the world to feel the pains.\\nBarbie's in her dream house, living in her bubble,\\nOppenheimer's in the lab, making atoms shuffle.\\n\\nBarbie, you're plastic, Oppenheimer's atomic,\\nYour rhymes are basic, his are supersonic.\\nBarbie, you're a doll, Oppenheimer's a legend,\\nIn this rap battle, it's clear who's the weapon.\\n\\nSo Barbie, step aside, Oppenheimer's in the zone,\\nIn this rap battle, he's sitting on the throne.\\nBarbie may be pretty, but Oppenheimer's the king,\\nIn this battle of wits, he's the one who'll bring the sting.\"},\n",
       "   'reference': {'must_mention': ['plastic', 'nuclear']}}},\n",
       " 'aggregate_metrics': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "\n",
    "@run_evaluator\n",
    "def must_mention(run, example) -> EvaluationResult:\n",
    "    prediction = run.outputs.get(\"text\") or \"\"\n",
    "    required = example.outputs.get(\"must_mention\") or []\n",
    "    score = all(phrase in prediction for phrase in required)\n",
    "    return EvaluationResult(key=\"must_mention\", score=score)\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[must_mention],\n",
    "    # You can also use a prebuilt evaluator\n",
    "    # by providing a name or RunEvalConfig.<configured evaluator>\n",
    "    evaluators=[\n",
    "        # You can specify an evaluator by name/enum.\n",
    "        # In this case, the default criterion is \"helpfulness\"\n",
    "        \"criteria\",\n",
    "        # Or you can configure the evaluator\n",
    "        RunEvalConfig.Criteria(\"harmfulness\"),\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\n",
    "                \"cliche\": \"Are the lyrics cliche?\"\n",
    "                \" Respond Y if they are, N if they're entirely unique.\"\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "client.run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=create_agent,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=\"agent-test-1\",\n",
    "    # Any experiment metadata can be specified here\n",
    "    project_metadata={\"version\": \"1.0.0\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
